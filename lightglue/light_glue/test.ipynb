{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ad3c79",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as a dll could not be loaded.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresDllLoad'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "from lightglue import LightGlue, SuperPoint, DISK, SIFT, ALIKED, DoGHardNet\n",
    "from lightglue.utils import load_image, rbd\n",
    "\n",
    "# SuperPoint+LightGlue\n",
    "extractor = SuperPoint(max_num_keypoints=2048).eval().cuda()  # load the extractor\n",
    "matcher = LightGlue(features='superpoint').eval().cuda()  # load the matcher\n",
    "\n",
    "# or DISK+LightGlue, ALIKED+LightGlue or SIFT+LightGlue\n",
    "extractor = DISK(max_num_keypoints=2048).eval().cuda()  # load the extractor\n",
    "matcher = LightGlue(features='disk').eval().cuda()  # load the matcher\n",
    "\n",
    "# load each image as a torch.Tensor on GPU with shape (3,H,W), normalized in [0,1]\n",
    "image0 = load_image('../../data_dir/A/e2.png').cuda()\n",
    "image1 = load_image('../../data_dir/B/e2.png').cuda()\n",
    "\n",
    "# extract local features\n",
    "feats0 = extractor.extract(image0)  # auto-resize the image, disable with resize=None\n",
    "feats1 = extractor.extract(image1)\n",
    "\n",
    "# match the features\n",
    "matches01 = matcher({'image0': feats0, 'image1': feats1})\n",
    "feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]  # remove batch dimension\n",
    "matches = matches01['matches']  # indices with shape (K,2)\n",
    "points0 = feats0['keypoints'][matches[..., 0]]  # coordinates in image #0, shape (K,2)\n",
    "points1 = feats1['keypoints'][matches[..., 1]]  # coordinates in image #1, shape (K,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe496913",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches01['scores'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = matches01['scores']          # (K,)\n",
    "matches = matches01['matches']        # (K, 2)\n",
    "\n",
    "# threshold (tune this)\n",
    "score_thresh = 0.7\n",
    "\n",
    "mask = scores > score_thresh\n",
    "\n",
    "matches = matches[mask]\n",
    "scores  = scores[mask]\n",
    "\n",
    "points0 = feats0['keypoints'][matches[:, 0]]\n",
    "points1 = feats1['keypoints'][matches[:, 1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260dbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightglue import viz2d\n",
    "kpts0, kpts1, matches = feats0[\"keypoints\"], feats1[\"keypoints\"], matches01[\"matches\"]\n",
    "m_kpts0, m_kpts1 = kpts0[matches[..., 0]], kpts1[matches[..., 1]]\n",
    "\n",
    "axes = viz2d.plot_images([image0, image1])\n",
    "viz2d.plot_matches(m_kpts0, m_kpts1, color=\"lime\", lw=0.2)\n",
    "viz2d.add_text(0, f'Stop after {matches01[\"stop\"]} layers', fs=20)\n",
    "\n",
    "kpc0, kpc1 = viz2d.cm_prune(matches01[\"prune0\"]), viz2d.cm_prune(matches01[\"prune1\"])\n",
    "viz2d.plot_images([image0, image1])\n",
    "viz2d.plot_keypoints([kpts0, kpts1], colors=[kpc0, kpc1], ps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d6901c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a60732e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as a dll could not be loaded.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresDllLoad'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "from lightglue import LightGlue, SuperPoint, DISK, SIFT, ALIKED, DoGHardNet\n",
    "from lightglue.utils import load_image, rbd\n",
    "\n",
    "# --- extractor & matcher (DISK example) ---\n",
    "extractor = DISK(max_num_keypoints=2048).eval().cuda()\n",
    "matcher = LightGlue(features='disk').eval().cuda()\n",
    "\n",
    "# --- load images ---\n",
    "image0 = load_image('../../data_dir/A/b2.png').cuda()\n",
    "image1 = load_image('../../data_dir/B/b2.png').cuda()\n",
    "\n",
    "# --- extract features ---\n",
    "feats0 = extractor.extract(image0)\n",
    "feats1 = extractor.extract(image1)\n",
    "\n",
    "# --- match ---\n",
    "matches01 = matcher({'image0': feats0, 'image1': feats1})\n",
    "\n",
    "# remove batch dimension\n",
    "feats0, feats1, matches01 = [rbd(x) for x in [feats0, feats1, matches01]]\n",
    "\n",
    "# =========================\n",
    "# SCORE THRESHOLDING (0.7)\n",
    "# =========================\n",
    "score_thresh = 0.8\n",
    "\n",
    "scores  = matches01['scores']     # (K,)\n",
    "matches = matches01['matches']    # (K, 2)\n",
    "\n",
    "mask = scores > score_thresh\n",
    "\n",
    "matches = matches[mask]\n",
    "scores  = scores[mask]\n",
    "\n",
    "# update matches01 so viz2d uses filtered matches\n",
    "matches01['matches'] = matches\n",
    "matches01['scores']  = scores\n",
    "\n",
    "# matched keypoints\n",
    "points0 = feats0['keypoints'][matches[:, 0]]\n",
    "points1 = feats1['keypoints'][matches[:, 1]]\n",
    "\n",
    "print(f\"Kept {len(matches)} matches with score > {score_thresh}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c568b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightglue import viz2d\n",
    "\n",
    "kpts0, kpts1 = feats0[\"keypoints\"], feats1[\"keypoints\"]\n",
    "matches = matches01[\"matches\"]\n",
    "\n",
    "m_kpts0 = kpts0[matches[..., 0]]\n",
    "m_kpts1 = kpts1[matches[..., 1]]\n",
    "\n",
    "axes = viz2d.plot_images([image0, image1])\n",
    "viz2d.plot_matches(m_kpts0, m_kpts1, color=\"lime\", lw=0.3)\n",
    "\n",
    "viz2d.add_text(\n",
    "    0,\n",
    "    f'{len(matches)} matches (score > 0.8)',\n",
    "    fs=18\n",
    ")\n",
    "\n",
    "# Optional: visualize pruning confidence\n",
    "kpc0 = viz2d.cm_prune(matches01[\"prune0\"])\n",
    "kpc1 = viz2d.cm_prune(matches01[\"prune1\"])\n",
    "\n",
    "viz2d.plot_images([image0, image1])\n",
    "viz2d.plot_keypoints([kpts0, kpts1], colors=[kpc0, kpc1], ps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Prepare matched points\n",
    "# -----------------------------\n",
    "pts0 = points0.detach().cpu().numpy().astype(np.float32)  # in image0 coords\n",
    "pts1 = points1.detach().cpu().numpy().astype(np.float32)  # in image1 coords\n",
    "\n",
    "if len(pts0) < 8:\n",
    "    raise ValueError(f\"Not enough matches for homography: {len(pts0)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Estimate homography H: image1 -> image0\n",
    "# -----------------------------\n",
    "H, inlier_mask = cv2.findHomography(pts1, pts0, cv2.RANSAC, 5.0)\n",
    "\n",
    "if H is None:\n",
    "    raise RuntimeError(\"Homography estimation failed. Lower threshold or check matches.\")\n",
    "\n",
    "inliers = int(inlier_mask.sum()) if inlier_mask is not None else 0\n",
    "print(\"Homography inliers:\", inliers, \"/\", len(pts0))\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Convert torch images (3,H,W in [0,1]) to OpenCV uint8 (H,W,3 BGR)\n",
    "# -----------------------------\n",
    "def torch_to_cv_u8(img_t: torch.Tensor) -> np.ndarray:\n",
    "    # img_t: (3,H,W), float [0,1]\n",
    "    img = (img_t.permute(1, 2, 0).detach().cpu().numpy() * 255.0).clip(0, 255).astype(np.uint8)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    return img\n",
    "\n",
    "img0_cv = torch_to_cv_u8(image0)\n",
    "img1_cv = torch_to_cv_u8(image1)\n",
    "\n",
    "h0, w0 = img0_cv.shape[:2]\n",
    "h1, w1 = img1_cv.shape[:2]\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Warp image1 into image0 geometry\n",
    "# -----------------------------\n",
    "img1_warp = cv2.warpPerspective(img1_cv, H, (w0, h0), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Compute overlap mask and crop to overlap bounding rectangle\n",
    "#    - overlap where both img0 and warped img1 have valid pixels\n",
    "# -----------------------------\n",
    "# Build validity mask for warped image1 (where pixels are not empty)\n",
    "mask1 = cv2.warpPerspective(np.ones((h1, w1), dtype=np.uint8) * 255, H, (w0, h0))\n",
    "mask0 = np.ones((h0, w0), dtype=np.uint8) * 255\n",
    "\n",
    "overlap = cv2.bitwise_and(mask0, mask1)\n",
    "\n",
    "ys, xs = np.where(overlap > 0)\n",
    "if len(xs) == 0 or len(ys) == 0:\n",
    "    raise RuntimeError(\"No overlap found after warping. Check matches / threshold.\")\n",
    "\n",
    "x_min, x_max = xs.min(), xs.max()\n",
    "y_min, y_max = ys.min(), ys.max()\n",
    "\n",
    "# Optional: tighten the crop a bit (remove border artifacts)\n",
    "margin = 2\n",
    "x_min = max(0, x_min + margin)\n",
    "y_min = max(0, y_min + margin)\n",
    "x_max = min(w0 - 1, x_max - margin)\n",
    "y_max = min(h0 - 1, y_max - margin)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Crop aligned images\n",
    "# -----------------------------\n",
    "img0_crop = img0_cv[y_min:y_max+1, x_min:x_max+1]\n",
    "img1_crop = img1_warp[y_min:y_max+1, x_min:x_max+1]\n",
    "\n",
    "print(\"Aligned crop size:\", img0_crop.shape, img1_crop.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Save results\n",
    "# -----------------------------\n",
    "cv2.imwrite(\"aligned_img0.png\", img0_crop)\n",
    "cv2.imwrite(\"aligned_img1.png\", img1_crop)\n",
    "\n",
    "print(\"Saved: aligned_img0.png and aligned_img1.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909d4fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "freelance38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
