#!/bin/bash

# Script to start both frontend and backend Docker containers
# Usage: ./start.sh [--build] [--gpu]

set -e

BUILD=false
GPU=false

# Parse arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        --build)
            BUILD=true
            shift
            ;;
        --gpu)
            GPU=true
            shift
            ;;
        *)
            echo "Unknown option: $1"
            echo "Usage: ./start.sh [--build] [--gpu]"
            exit 1
            ;;
    esac
done

echo "ðŸš€ Starting Change Detection Application..."
echo ""

# Check if docker-compose is available
if ! command -v docker-compose &> /dev/null && ! command -v docker &> /dev/null; then
    echo "âŒ Error: Docker is not installed or not in PATH"
    exit 1
fi

# Use docker compose (newer) or docker-compose (older)
if command -v docker &> /dev/null && docker compose version &> /dev/null; then
    COMPOSE_CMD="docker compose"
elif command -v docker-compose &> /dev/null; then
    COMPOSE_CMD="docker-compose"
else
    echo "âŒ Error: docker-compose is not available"
    exit 1
fi

# Build if requested
if [ "$BUILD" = true ]; then
    echo "ðŸ”¨ Building Docker images..."
    $COMPOSE_CMD build
    echo ""
fi

# Check for GPU and NVIDIA Container Toolkit
echo "ðŸ” Checking for GPU and NVIDIA Container Toolkit..."
NVIDIA_CONTAINER_TOOLKIT=false

# Check if nvidia-smi works on host
if command -v nvidia-smi &> /dev/null && nvidia-smi &> /dev/null; then
    echo "   âœ… NVIDIA GPU detected on host"
    
    # Test if NVIDIA Container Toolkit is installed (Docker can access GPU)
    if docker run --rm --gpus all nvidia/cuda:12.4.0-base-ubuntu22.04 nvidia-smi &> /dev/null; then
        echo "   âœ… NVIDIA Container Toolkit is installed - GPU will be available in containers"
        NVIDIA_CONTAINER_TOOLKIT=true
    else
        echo "   âš ï¸  NVIDIA Container Toolkit NOT installed - containers will run on CPU"
        echo "   ðŸ’¡ Install it with: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html"
        NVIDIA_CONTAINER_TOOLKIT=false
    fi
else
    echo "   â„¹ï¸  No GPU detected - will run on CPU"
    NVIDIA_CONTAINER_TOOLKIT=false
fi

# Create temporary docker-compose override for GPU if available
if [ "$GPU" = true ] || [ "$NVIDIA_CONTAINER_TOOLKIT" = true ]; then
    echo "ðŸ“¦ Starting containers with GPU support..."
    export CUDA_VISIBLE_DEVICES=0
    # Create temporary override file to enable GPU
    cat > docker-compose.override.yml <<EOF
version: '3.8'
services:
  backend:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
EOF
else
    echo "ðŸ“¦ Starting containers on CPU..."
    export CUDA_VISIBLE_DEVICES=""
    # Remove override file if it exists
    rm -f docker-compose.override.yml
fi

$COMPOSE_CMD up -d

# Clean up override file after starting (optional, can leave it)
# rm -f docker-compose.override.yml

echo ""
echo "âœ… Services started!"
echo ""
echo "ðŸ“ Access the application:"
echo "   Frontend: http://localhost:3000"
echo "   Backend API: http://localhost:8000"
echo "   API Docs: http://localhost:8000/docs"
echo ""
echo "ðŸ“Š View logs:"
echo "   $COMPOSE_CMD logs -f"
echo ""
echo "ðŸ›‘ Stop services:"
echo "   $COMPOSE_CMD down"
echo ""

